{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Gerais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas para Plotar GrÃ¡ficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas para PreparaÃ§Ã£o dos Dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Biblioteca para ClassificaÃ§Ã£o\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Bibliotecas para PÃ³s Processamento das ClassificaÃ§Ãµes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "\n",
    "# Carregando os dados\n",
    "train_data_url = 'https://raw.githubusercontent.com/Spogis/SimpleClassification/master/Datasets/train_data.csv'\n",
    "validation_data_url = 'https://raw.githubusercontent.com/Spogis/SimpleClassification/master/Datasets/test_data.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_url)\n",
    "validation_data = pd.read_csv(validation_data_url)\n",
    "\n",
    "# Especificando as colunas categÃ³ricas e numÃ©ricas\n",
    "categorical_features = ['Title', 'Sex', 'TicketAppearances', 'CabinPrefix', 'IsAlone', 'Embarked']\n",
    "numerical_features = ['Pclass', 'Fare', 'FamilySize', 'SibSp', 'Parch']\n",
    "\n",
    "# CodificaÃ§Ã£o das variÃ¡veis categÃ³ricas\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    combined_data = pd.concat([train_data[feature], validation_data[feature]], axis=0)\n",
    "    combined_data_encoded = label_encoder.fit_transform(combined_data)\n",
    "    train_data[feature] = combined_data_encoded[:len(train_data)]\n",
    "    validation_data[feature] = combined_data_encoded[len(train_data):]\n",
    "\n",
    "# Obter a ordem das colunas para entrada de dados (categÃ³ricas e numÃ©ricas)\n",
    "feature_order = categorical_features + numerical_features\n",
    "\n",
    "# Exibindo a ordem das features para a entrada de dados\n",
    "print(\"Ordem de entrada dos dados no modelo:\")\n",
    "print(feature_order)\n",
    "\n",
    "# PadronizaÃ§Ã£o das variÃ¡veis numÃ©ricas\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data[numerical_features])\n",
    "train_data[numerical_features] = scaler.transform(train_data[numerical_features])\n",
    "validation_data[numerical_features] = scaler.transform(validation_data[numerical_features])\n",
    "\n",
    "# Separando as variÃ¡veis independentes da variÃ¡vel alvo (ClassificaÃ§Ã£o)\n",
    "y = train_data['Survived']\n",
    "X = train_data[categorical_features + numerical_features]\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento(80%) e teste(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definindo o modelo XGBClassifier com parÃ¢metros fixos\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,      # NÃºmero de Ã¡rvores\n",
    "    max_depth=5,           # Profundidade mÃ¡xima da Ã¡rvore\n",
    "    learning_rate=0.05,    # Taxa de aprendizado\n",
    "    subsample=0.8,         # FraÃ§Ã£o de amostras usadas para cada Ã¡rvore\n",
    "    colsample_bytree=0.8,  # FraÃ§Ã£o de colunas usadas para cada Ã¡rvore\n",
    "    min_child_weight=2,    # Peso mÃ­nimo das instÃ¢ncias em cada folha\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Treinando o modelo\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0704c5",
   "metadata": {
    "cell_marker": "########################################################################################################################"
   },
   "source": [
    "A partir daqui fazemos o pÃ³s processamento das anÃ¡lises\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo no conjunto de teste\n",
    "test_accuracy = xgb.score(X_test, y_test)\n",
    "print(f\"AcurÃ¡cia no conjunto de teste: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Fazendo previsÃµes com o modelo treinado\n",
    "predictions = xgb.predict(X)\n",
    "\n",
    "# Calculando e plotando a matriz de confusÃ£o\n",
    "conf_matrix = confusion_matrix(y, predictions)\n",
    "conf_matrix_percentage_per_class = conf_matrix / np.sum(conf_matrix, axis=1, keepdims=True) * 100\n",
    "annot = np.array([[\"{:.1f}%\".format(val) for val in row] for row in conf_matrix_percentage_per_class])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix_percentage_per_class, annot=annot, fmt=\"\", cmap=\"Blues\",\n",
    "            xticklabels=['Not Survived', 'Survived'],\n",
    "            yticklabels=['Not Survived', 'Survived'],\n",
    "            square=True,\n",
    "            cbar_kws={\"shrink\": 0.75},\n",
    "            annot_kws={\"size\": 14}, linewidth=.5)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "# Salvar a figura da matriz de confusÃ£o\n",
    "plt.savefig('confusion_matrix.png', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "# ImportÃ¢ncia das caracterÃ­sticas\n",
    "feature_importances = xgb.feature_importances_\n",
    "features = categorical_features + numerical_features\n",
    "importances_df = pd.DataFrame({'Features': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Features', data=importances_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "# Salvar a figura da importÃ¢ncia das caracterÃ­sticas\n",
    "plt.savefig('feature_importance.png', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "# Calculando as probabilidades para a classe positiva\n",
    "y_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculando a AUC\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC: {auc_score:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plotando a curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal de sorte\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC_curve.png', dpi=600)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.savefig('Precision_Recall_curve.png', dpi=600)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361d7fd",
   "metadata": {
    "cell_marker": "########################################################################################################################"
   },
   "source": [
    "Teste de previsÃ£o com 5 linhas aleatÃ³rias do dataset original\n",
    "#######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando 5 linhas aleatÃ³rias do conjunto de validaÃ§Ã£o\n",
    "random_rows = validation_data.sample(n=5, random_state=42)\n",
    "\n",
    "# Obtendo os PassengerId e os nomes das linhas aleatÃ³rias\n",
    "passenger_ids = random_rows['PassengerId'].values\n",
    "names = random_rows['Name'].values\n",
    "\n",
    "# Obtendo os valores verdadeiros para comparaÃ§Ã£o\n",
    "true_values = random_rows['Survived'].values\n",
    "\n",
    "# Aplicando as mesmas transformaÃ§Ãµes de codificaÃ§Ã£o (LabelEncoder) e padronizaÃ§Ã£o (StandardScaler)\n",
    "# Codificando variÃ¡veis categÃ³ricas\n",
    "for feature in categorical_features:\n",
    "    combined_data = pd.concat([train_data[feature], validation_data[feature]], axis=0)\n",
    "    combined_data_encoded = label_encoder.fit_transform(combined_data)\n",
    "    random_rows[feature] = label_encoder.transform(random_rows[feature])\n",
    "\n",
    "# Padronizando variÃ¡veis numÃ©ricas\n",
    "random_rows[numerical_features] = scaler.transform(random_rows[numerical_features])\n",
    "\n",
    "# Selecionando as colunas de interesse (categÃ³ricas e numÃ©ricas)\n",
    "random_rows_X = random_rows[categorical_features + numerical_features]\n",
    "\n",
    "# Fazendo as previsÃµes com as linhas aleatÃ³rias\n",
    "random_predictions = xgb.predict(random_rows_X)\n",
    "\n",
    "print()\n",
    "# Exibindo os resultados\n",
    "for passenger_id, name, true_value, prediction in zip(passenger_ids, names, true_values, random_predictions):\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Valor verdadeiro: {'Sobreviveu' if true_value == 1 else 'NÃ£o sobreviveu'}\")\n",
    "    print(f\"PrediÃ§Ã£o: {'Sobreviveu' if prediction == 1 else 'NÃ£o sobreviveu'}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
